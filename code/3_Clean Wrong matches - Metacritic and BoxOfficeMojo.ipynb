{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Wrong Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-01T03:15:09.534487Z",
     "start_time": "2017-12-01T03:15:08.442273Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-01T03:15:09.592591Z",
     "start_time": "2017-12-01T03:15:09.536433Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thisyear = '2016'\n",
    "df = pd.read_csv('mc'+ thisyear +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-01T03:15:11.452317Z",
     "start_time": "2017-12-01T03:15:11.438570Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = df[df['meta_movie_name'] == 'error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-01T03:15:11.826413Z",
     "start_time": "2017-12-01T03:15:11.820226Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noerror = df[df['meta_movie_name'] != 'error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-01T03:15:12.231100Z",
     "start_time": "2017-12-01T03:15:12.220523Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrongdate = noerror[~noerror['release_date'].str.contains(thisyear)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-01T03:15:12.595809Z",
     "start_time": "2017-12-01T03:15:12.589846Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrongdate = wrongdate.drop_duplicates(subset='rank', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-01T03:15:12.993670Z",
     "start_time": "2017-12-01T03:15:12.988046Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_out = error.append(wrongdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-01T03:15:13.443480Z",
     "start_time": "2017-12-01T03:15:13.437822Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_out.to_csv('mc_error_'+thisyear+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get MC true matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T01:23:20.471992Z",
     "start_time": "2017-10-27T01:23:20.468082Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T03:29:26.979503Z",
     "start_time": "2017-10-27T03:29:26.925932Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thisyear = '2016'\n",
    "df_error = pd.read_csv('mc_error_'+ thisyear +'v2.csv')\n",
    "df= pd.read_csv('mc'+ thisyear+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T03:29:27.476715Z",
     "start_time": "2017-10-27T03:29:27.461904Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df, df_error,  how='left', left_on=['rank'], right_on = ['rank'])\n",
    "df_right = df_merge[df_merge.moviename_y.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T03:30:15.940533Z",
     "start_time": "2017-10-27T03:29:57.103226Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Now Pronounce You Chuck and Larry ^^^^^ i-now-pronounce-you-chuck-larry\n",
      "METANAME @@@@  I Now Pronounce You Chuck & Larry\n",
      "Halloween (2007) ^^^^^ halloween-2007\n",
      "METANAME @@@@  Halloween (2007)\n",
      "The Water Horse: Legend of the Deep ^^^^^ the-water-horse\n",
      "METANAME @@@@  The Water Horse\n",
      "Tyler Perry's Why Did I Get Married? ^^^^^ why-did-i-get-married\n",
      "METANAME @@@@  Why Did I Get Married?\n",
      "Aliens Vs. Predator - Requiem ^^^^^ avpr-aliens-vs-predator---requiem\n",
      "METANAME @@@@  AVPR: Aliens vs Predator - Requiem\n",
      "The Number 23 ^^^^^ the-number-23\n",
      "ERROR %%%  the-number-23\n",
      "Mr. Bean's Holiday ^^^^^ mr-beans-vacation\n",
      "METANAME @@@@  Mr. Bean's Vacation\n",
      "Tyler Perry's Daddy's Little Girls ^^^^^ daddys-little-girls\n",
      "METANAME @@@@  Daddy's Little Girls\n",
      "The Hills Have Eyes 2 ^^^^^ the-hills-have-eyes-ii\n",
      "METANAME @@@@  The Hills Have Eyes II\n",
      "Dragon Wars ^^^^^ dragon-wars-d-war\n",
      "METANAME @@@@  Dragon Wars: D-War\n",
      "Pathfinder: Legend of the Ghost Warrior ^^^^^ pathfinder\n",
      "METANAME @@@@  Pathfinder\n"
     ]
    }
   ],
   "source": [
    "output_list = []\n",
    "for i in range(0,len(df_error)):\n",
    "    moviename = df_error.iloc[i]['moviename']\n",
    "    rank = df_error.iloc[i]['rank']\n",
    "    name = df_error.iloc[i]['link']\n",
    "    print (moviename, '^^^^^', name)\n",
    "    link1 = 'http://www.metacritic.com/movie/'\n",
    "    link2 = '/critic-reviews'\n",
    "    link = link1 + name + link2\n",
    "    \n",
    "    headers = {'User-Agent' : 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6'} \n",
    "    r = requests.get(link, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    try:\n",
    "        meta_movie_name = soup.find('div', class_='product_page_title upper pad_top2 pad_btm_half oswald').text.strip()\n",
    "        num_crit = soup.find('span', class_='based_on').text.strip()\n",
    "        error = 0\n",
    "        print ('METANAME @@@@ ', meta_movie_name)\n",
    "    except:\n",
    "        error = 1\n",
    "        print ('ERROR %%% ', name)\n",
    "        output_list.append([rank, moviename, 'error'])\n",
    "    \n",
    "    if error == 0:\n",
    "        release = soup.find('td', class_='left inset_right2 product_info lighter oswald upper pad_btm1')\n",
    "        release_date = release.find('span', class_='release_date').text.replace('Release Date:','').strip()\n",
    "        total_score = soup.find('td', class_='num_wrapper').text.strip()\n",
    "        try:\n",
    "            num_crit = soup.find('span', class_='based_on').text.strip()\n",
    "            num_crit = int(re.search(r'\\d+', num_crit).group())\n",
    "        except:\n",
    "            num_crit = ''\n",
    "        try:\n",
    "            positive = soup.find('div', class_='chart positive')\n",
    "            positive = positive.find('div', class_='count fr').text.strip()\n",
    "            mixed = soup.find('div', class_='chart mixed')\n",
    "            mixed = mixed.find('div', class_='count fr').text.strip()\n",
    "            negative = soup.find('div', class_='chart negative')\n",
    "            negative = negative.find('div', class_='count fr').text.strip()\n",
    "        except:\n",
    "            positive = ''\n",
    "            mixed = ''\n",
    "            negative = ''\n",
    "            \n",
    "        critics = soup.find_all('div', class_='review pad_top1 pad_btm1')\n",
    "        for each in critics:\n",
    "            iscore = each.find('div', class_='metascore_w').text.strip()\n",
    "            try:\n",
    "                source = each.find('span', class_='source').text.strip()\n",
    "            except:\n",
    "                source = ''\n",
    "            try:\n",
    "                source_link = 'http://www.metacritic.com' + each.find('span', class_='source').a['href']\n",
    "            except:\n",
    "                source_link = ''\n",
    "            try:\n",
    "                author = each.find('span', class_='author').text.strip()\n",
    "            except:\n",
    "                author = ''\n",
    "            try:\n",
    "                author_link = 'http://www.metacritic.com' + each.find('span', class_='author').a['href']\n",
    "            except:\n",
    "                author_link = ''\n",
    "            try: \n",
    "                date = each.find('span', class_='date').text.strip()\n",
    "            except:\n",
    "                date = ''\n",
    "            try:\n",
    "                summary = each.find('div', class_='summary').a.text.strip()\n",
    "            except:\n",
    "                summary = ''\n",
    "            output_list.append([rank, moviename, meta_movie_name, release_date, total_score, num_crit, positive, mixed, negative,\n",
    "                          iscore, source, source_link, author, author_link, date, summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T03:30:16.149078Z",
     "start_time": "2017-10-27T03:30:15.942545Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santostang/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "new_add = pd.DataFrame(output_list, columns=['rank', 'moviename', 'meta_movie_name', 'release_date', 'total_score', \n",
    "                                   'num_crit', 'positive', 'mixed', 'negative', 'iscore', 'source', 'source_link', 'author', 'author_link', 'date', 'summary'])\n",
    "df_right.drop(['moviename_y', 'link'], axis=1, inplace=True)\n",
    "df_out = df_right.append(new_add, ignore_index=True)\n",
    "df_out.to_csv('mc2_'+ thisyear +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
